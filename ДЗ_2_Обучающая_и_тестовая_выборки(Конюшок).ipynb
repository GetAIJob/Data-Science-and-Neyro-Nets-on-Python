{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ДЗ_2_Обучающая и тестовая выборки(Конюшок).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "19eosihnwr9lIFuUM9HePfwRX-j17ryW1",
      "authorship_tag": "ABX9TyMW8gNWQVVodOz9PZJez2ZT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ikonushok/My_studying_Data-Science-and-Neyro-Nets-on-Python/blob/master/%D0%94%D0%97_2_%D0%9E%D0%B1%D1%83%D1%87%D0%B0%D1%8E%D1%89%D0%B0%D1%8F_%D0%B8_%D1%82%D0%B5%D1%81%D1%82%D0%BE%D0%B2%D0%B0%D1%8F_%D0%B2%D1%8B%D0%B1%D0%BE%D1%80%D0%BA%D0%B8(%D0%9A%D0%BE%D0%BD%D1%8E%D1%88%D0%BE%D0%BA).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cXSr-M76vdD",
        "colab_type": "text"
      },
      "source": [
        "# LIGHT\n",
        "Создайте модель для распознавания рукописных цифр из набора MNIST (можно воспользоваться ноутбуком 1-го занятия) и проведите ряд тестов:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aoOzI1k6z44",
        "colab_type": "text"
      },
      "source": [
        "## Запустите сеть с различными размерами обучающей выборки:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_mWpt8pva-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Открываем необходимые библиотеки\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
        "from tensorflow.keras import utils # для to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping # для остановки при начале переобучения\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import pylab\n",
        "import matplotlib.pyplot as plt\n",
        "from  PIL import Image\n",
        "# отрисовывать в ноутбуке\n",
        "%matplotlib inline "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJGSMsxx0EFF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e5e5c79b-f78d-48f0-f43b-621ed105711e"
      },
      "source": [
        "# Загрузка данных\n",
        "(x_train_org, y_train_org), (x_test_org, y_test_org) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRfngXzM7MsX",
        "colab_type": "text"
      },
      "source": [
        "###Обучающие выборки: от 60.000 до 10 образцов\n",
        "для сравнения оставил и первоначальную выборку в 60.000 образцов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUT5sDKdEyBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# необходимые переменные\n",
        "N = [60000, 50000, 10000, 5000, 1000, 500, 250, 100, 50, 10] # Размеры тестовых выборок\n",
        "N_test = 10000 # доля тестовой выборки от обучающей\n",
        "N_batch_size = 128\n",
        "N_Dence_relu = 800\n",
        "N_epochs = 25 # от переобучения спасет EarlyStopping\n",
        "data = [[0, 0, 800, 'relu', N_batch_size, 0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e39M3BpJ2M4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "31e5f323-bd69-4a09-89e9-10f1d605e2ac"
      },
      "source": [
        "for i in N:\n",
        "  # берем нужную выборку\n",
        "  x_train = x_train_org[0: i]\n",
        "  y_train = y_train_org[0: i]\n",
        "  # меняем формат картинок с 28х28 на 784х1\n",
        "  x_train = x_train.reshape(i, 784)\n",
        "  x_test = x_test_org.reshape(N_test, 784)  # тоже можно менять размер пропорционально N\n",
        "  # нормализуем данные\n",
        "  x_train = x_train.astype('float32')\n",
        "  x_train = x_train / 255 # делим на 255 чтобы диапазон был от 0 до 1\n",
        "  x_test = x_test.astype('float32')\n",
        "  x_test = x_test / 255 # делим на 255 чтобы диапазон был от 0 до 1\n",
        "  # преобразуем ответы в формат one_hot_encoding\n",
        "  y_train = utils.to_categorical(y_train, 10)\n",
        "  y_test = utils.to_categorical(y_test_org, 10)\n",
        "  # проверяем размеры\n",
        "  #print('x_train:' , x_train.shape, '\\t'\n",
        "  #      'y_train:' , y_train.shape, '\\t'\n",
        "  #      'x_test:' , x_test.shape, '\\t'\n",
        "  #      'y_test:' , y_test.shape, '\\n')\n",
        "\n",
        "  # создаем нейросеть\n",
        "  model=Sequential() # нейросеть прямого распространения\n",
        "  model.add(Dense(N_Dence_relu, input_dim=784, activation='relu')) # добавили полносвязный слой\n",
        "  model.add(Dense(10, activation='softmax')) # полносвязный слой на выходе\n",
        "  # компилируем\n",
        "  model.compile(loss='categorical_crossentropy', \n",
        "                optimizer='adam', \n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  # задание условий установки обучения\n",
        "  early_stopping = EarlyStopping(monitor = 'val_loss',\n",
        "                                 patience=1, # 1 мало, но существенно ускоряет процесс\n",
        "                                 # при этом потеря в качестве очень мала\n",
        "                                 # Число эпох, в течении которых должен ухудшаться val_loss\n",
        "                                 restore_best_weights = True)\n",
        "\n",
        "  # обучаем сеть\n",
        "  history = model.fit(x_train, y_train,\n",
        "                      batch_size=N_batch_size, \n",
        "                      epochs=N_epochs, \n",
        "                      verbose=0, # не показывать процесс обучения\n",
        "                      validation_split=0.2,\n",
        "                      callbacks=[early_stopping])\n",
        "\n",
        "  # готовим отчетную таблицу\n",
        "  data = data + [[x_train.shape, x_test.shape, N_Dence_relu, 'linear', N_batch_size, \n",
        "                  round(model.evaluate(x_test, y_test, verbose = 0)[1], 3)]]\n",
        "  \n",
        "  # проверяем результат обучения на тестовой выборке\n",
        "  #print(\"Поверяем результат обучения для выборки: \", i)\n",
        "  #model.evaluate(x_test, y_test)[1]\n",
        "\n",
        "# Печатаем отчет\n",
        "df = pd.DataFrame(data[1:], \n",
        "                  columns = ['train', 'test', 'neurons', 'activation', 'batch_size','val_accuracy'])\n",
        "df\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "      <th>neurons</th>\n",
              "      <th>activation</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(60000, 784)</td>\n",
              "      <td>(10000, 784)</td>\n",
              "      <td>800</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(50000, 784)</td>\n",
              "      <td>(10000, 784)</td>\n",
              "      <td>800</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(10000, 784)</td>\n",
              "      <td>(10000, 784)</td>\n",
              "      <td>800</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(5000, 784)</td>\n",
              "      <td>(10000, 784)</td>\n",
              "      <td>800</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(1000, 784)</td>\n",
              "      <td>(10000, 784)</td>\n",
              "      <td>800</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(500, 784)</td>\n",
              "      <td>(10000, 784)</td>\n",
              "      <td>800</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>(250, 784)</td>\n",
              "      <td>(10000, 784)</td>\n",
              "      <td>800</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>(100, 784)</td>\n",
              "      <td>(10000, 784)</td>\n",
              "      <td>800</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>(50, 784)</td>\n",
              "      <td>(10000, 784)</td>\n",
              "      <td>800</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>(10, 784)</td>\n",
              "      <td>(10000, 784)</td>\n",
              "      <td>800</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.369</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          train          test  neurons activation  batch_size  val_accuracy\n",
              "0  (60000, 784)  (10000, 784)      800     linear         128         0.979\n",
              "1  (50000, 784)  (10000, 784)      800     linear         128         0.979\n",
              "2  (10000, 784)  (10000, 784)      800     linear         128         0.945\n",
              "3   (5000, 784)  (10000, 784)      800     linear         128         0.936\n",
              "4   (1000, 784)  (10000, 784)      800     linear         128         0.869\n",
              "5    (500, 784)  (10000, 784)      800     linear         128         0.791\n",
              "6    (250, 784)  (10000, 784)      800     linear         128         0.760\n",
              "7    (100, 784)  (10000, 784)      800     linear         128         0.676\n",
              "8     (50, 784)  (10000, 784)      800     linear         128         0.610\n",
              "9     (10, 784)  (10000, 784)      800     linear         128         0.369"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNRTANysURk5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "29fc1d28-144e-40ae-abff-29a4fa875089"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_18 (Dense)             (None, 800)               628000    \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                8010      \n",
            "=================================================================\n",
            "Total params: 636,010\n",
            "Trainable params: 636,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoSi2T0zOmxf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "8bd2bfec-a0e4-4ce1-8378-f7d9dc7bced0"
      },
      "source": [
        "# код не запускать!\n",
        "# Сделано без EarlyStopping"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>samples</th>\n",
              "      <th>neurons</th>\n",
              "      <th>activation</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60000</td>\n",
              "      <td>800</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50000</td>\n",
              "      <td>800</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10000</td>\n",
              "      <td>800</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>500</td>\n",
              "      <td>800</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.824</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   samples  neurons activation  batch_size  val_accuracy\n",
              "0    60000      800     linear         128         0.982\n",
              "1    50000      800     linear         128         0.980\n",
              "2    10000      800     linear         128         0.956\n",
              "3      500      800     linear         128         0.824"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMx3Rf3ZNUsT",
        "colab_type": "text"
      },
      "source": [
        "### Вывод:\n",
        "\n",
        "1. Эксперимент с EarlyStopping показал, что 1 дает снижение качества обучения на 1%, но patience=3 практически не снижает качество обучения, заметно его ускоряя!\n",
        "2. Эффективная выборка для обучения такой нейрости должна быть не менее 5.000 образцов\n",
        "3. Было бы хорошо визуализировать падение val_accuracy в зависимости от размера выборки, но пока не разобрался как \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MgAcBIx7oSt",
        "colab_type": "text"
      },
      "source": [
        "##Создайте сеть следующей архитектуры:\n",
        "a. 4 Dense слоя\n",
        "\n",
        "b. 3 Dropout слоя\n",
        "\n",
        "c. 3 BatchNormalization слоя"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36NKudpOVhdk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# необходимые переменные\n",
        "N = [60000, 50000, 10000, 5000, 1000, 500, 250, 100, 50, 10] # Размеры тестовых выборок\n",
        "N_test = 10000 # доля тестовой выборки от обучающей\n",
        "N_batch_size = 128\n",
        "N_Dence_relu = 800\n",
        "N_epochs = 25 # от переобучения спасет EarlyStopping\n",
        "data = [[0, 0, 800, 'relu', N_batch_size, 0]]\n",
        "\n",
        "k_Dropout = 0.3 # доля отключаемых для обучения нейронов"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCL37MkQJ6nF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "b5d067be-9cc3-4266-f8ce-0ae1519957a0"
      },
      "source": [
        "for i in N:\n",
        "  # берем нужную выборку\n",
        "  x_train = x_train_org[0: i]\n",
        "  y_train = y_train_org[0: i]\n",
        "  # меняем формат картинок с 28х28 на 784х1\n",
        "  x_train = x_train.reshape(i, 784)\n",
        "  x_test = x_test_org.reshape(N_test, 784)\n",
        "  # нормализуем данные\n",
        "  x_train = x_train.astype('float32')\n",
        "  x_train = x_train / 255 # делим на 255 чтобы диапазон был от 0 до 1\n",
        "  x_test = x_test.astype('float32')\n",
        "  x_test = x_test / 255 # делим на 255 чтобы диапазон был от 0 до 1\n",
        "  # преобразуем ответы в формат one_hot_encoding\n",
        "  y_train = utils.to_categorical(y_train, 10)\n",
        "  y_test = utils.to_categorical(y_test_org, 10)\n",
        "\n",
        "  # создаем нейросеть\n",
        "  model2=Sequential() # нейросеть прямого распространения\n",
        "  #1\n",
        "  model2.add(Dropout(k_Dropout))\n",
        "  model2.add(Dense(N_Dence_relu, input_dim=784, activation='relu'))\n",
        "  #2\n",
        "  model2.add(Dropout(k_Dropout))\n",
        "  model2.add(BatchNormalization())\n",
        "  model2.add(Dense(N_Dence_relu/2, input_dim=784, activation='relu')) # число нейронов/2\n",
        "  #3\n",
        "  model2.add(Dropout(k_Dropout))\n",
        "  model2.add(BatchNormalization())\n",
        "  model2.add(Dense(N_Dence_relu/4, input_dim=784, activation='relu')) # число нейронов/4\n",
        "  #4 \n",
        "  model2.add(BatchNormalization())\n",
        "  model2.add(Dense(10, activation='softmax')) # полносвязный слой на выходе\n",
        "  # компилируем\n",
        "  model2.compile(loss='categorical_crossentropy', \n",
        "                optimizer='adam', \n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  # задание условий установки обучения\n",
        "  early_stopping = EarlyStopping(monitor = 'val_loss',\n",
        "                                 patience=1, # лучше 3\n",
        "                                 restore_best_weights = True)\n",
        "  # обучаем сеть\n",
        "  model2.fit(x_train, y_train, \n",
        "            batch_size=N_batch_size, \n",
        "            epochs=N_epochs, \n",
        "            verbose=0, # не показывать процесс обучения\n",
        "            validation_split=0.2,\n",
        "            callbacks=[early_stopping])\n",
        "  \n",
        "  # готовим отчетную таблицу\n",
        "  data = data + [[x_train.shape, x_test.shape, N_Dence_relu, 'linear', N_batch_size, \n",
        "                  round(model2.evaluate(x_test, y_test, verbose = 0)[1], 3)]]\n",
        "\n",
        "\n",
        "# Печатаем отчет\n",
        "df = pd.DataFrame(data[1:], \n",
        "                  columns = ['train', 'test', 'neurons', 'activation', 'batch_size','val_accuracy'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "      <th>neurons</th>\n",
              "      <th>activation</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(60000, 784)</td>\n",
              "      <td>(10000, 784)</td>\n",
              "      <td>800</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(50000, 784)</td>\n",
              "      <td>(10000, 784)</td>\n",
              "      <td>800</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(10000, 784)</td>\n",
              "      <td>(10000, 784)</td>\n",
              "      <td>800</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(5000, 784)</td>\n",
              "      <td>(10000, 784)</td>\n",
              "      <td>800</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(1000, 784)</td>\n",
              "      <td>(10000, 784)</td>\n",
              "      <td>800</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(500, 784)</td>\n",
              "      <td>(10000, 784)</td>\n",
              "      <td>800</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>(250, 784)</td>\n",
              "      <td>(10000, 784)</td>\n",
              "      <td>800</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>(100, 784)</td>\n",
              "      <td>(10000, 784)</td>\n",
              "      <td>800</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>(50, 784)</td>\n",
              "      <td>(10000, 784)</td>\n",
              "      <td>800</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>(10, 784)</td>\n",
              "      <td>(10000, 784)</td>\n",
              "      <td>800</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.415</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          train          test  neurons activation  batch_size  val_accuracy\n",
              "0  (60000, 784)  (10000, 784)      800     linear         128         0.979\n",
              "1  (50000, 784)  (10000, 784)      800     linear         128         0.973\n",
              "2  (10000, 784)  (10000, 784)      800     linear         128         0.953\n",
              "3   (5000, 784)  (10000, 784)      800     linear         128         0.941\n",
              "4   (1000, 784)  (10000, 784)      800     linear         128         0.873\n",
              "5    (500, 784)  (10000, 784)      800     linear         128         0.816\n",
              "6    (250, 784)  (10000, 784)      800     linear         128         0.729\n",
              "7    (100, 784)  (10000, 784)      800     linear         128         0.574\n",
              "8     (50, 784)  (10000, 784)      800     linear         128         0.403\n",
              "9     (10, 784)  (10000, 784)      800     linear         128         0.415"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWVZJmE_bzcu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "outputId": "fd447d33-b3d7-43bc-86a4-5b7fdd8523c1"
      },
      "source": [
        "print(model2.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_126\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dropout_201 (Dropout)        (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_386 (Dense)            (None, 800)               628000    \n",
            "_________________________________________________________________\n",
            "dropout_202 (Dropout)        (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_201 (Bat (None, 800)               3200      \n",
            "_________________________________________________________________\n",
            "dense_387 (Dense)            (None, 400)               320400    \n",
            "_________________________________________________________________\n",
            "dropout_203 (Dropout)        (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_202 (Bat (None, 400)               1600      \n",
            "_________________________________________________________________\n",
            "dense_388 (Dense)            (None, 200)               80200     \n",
            "_________________________________________________________________\n",
            "batch_normalization_203 (Bat (None, 200)               800       \n",
            "_________________________________________________________________\n",
            "dense_389 (Dense)            (None, 10)                2010      \n",
            "=================================================================\n",
            "Total params: 1,036,210\n",
            "Trainable params: 1,033,410\n",
            "Non-trainable params: 2,800\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-ThhIrs7_Nj",
        "colab_type": "text"
      },
      "source": [
        "------\n",
        "###Выводы по результатам проведенных тестов.\n",
        "1. BatchNormalization в данном случае вообще не нужен\n",
        "2. Думал постараться загнать создание нейросети в функцию, но, похоже, тут тоже не будет выигрыша\n",
        "3. Dropout может быть полезен. Особенно при небольих выборках"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPW14psl8Xjb",
        "colab_type": "text"
      },
      "source": [
        "# PRO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4Boz9wa8U6b",
        "colab_type": "text"
      },
      "source": [
        "##Вариант 1\n",
        "Повысьте точность модели по обнаружению мин до 90 % на тестовой выборке. Можно использовать различные варианты слоев Dropout и BatchNormalization. Можно менять количество примеров в обучающей и проверочной выборках, но нельзя менять количество примеров в тестовой."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0sq2lIMJ7f1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "c298ad1f-4c9a-4c49-fddb-91cab5f62010"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Data Science и нейронные сети на Python/Занятие_2_Обучающая и тестовая выборки/base2/sonar.csv\", header=None)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.1609</td>\n",
              "      <td>0.1582</td>\n",
              "      <td>0.2238</td>\n",
              "      <td>0.0645</td>\n",
              "      <td>0.0660</td>\n",
              "      <td>0.2273</td>\n",
              "      <td>0.3100</td>\n",
              "      <td>0.2999</td>\n",
              "      <td>0.5078</td>\n",
              "      <td>0.4797</td>\n",
              "      <td>0.5783</td>\n",
              "      <td>0.5071</td>\n",
              "      <td>0.4328</td>\n",
              "      <td>0.5550</td>\n",
              "      <td>0.6711</td>\n",
              "      <td>0.6415</td>\n",
              "      <td>0.7104</td>\n",
              "      <td>0.8080</td>\n",
              "      <td>0.6791</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>0.1307</td>\n",
              "      <td>0.2604</td>\n",
              "      <td>0.5121</td>\n",
              "      <td>0.7547</td>\n",
              "      <td>0.8537</td>\n",
              "      <td>0.8507</td>\n",
              "      <td>0.6692</td>\n",
              "      <td>0.6097</td>\n",
              "      <td>0.4943</td>\n",
              "      <td>0.2744</td>\n",
              "      <td>0.0510</td>\n",
              "      <td>0.2834</td>\n",
              "      <td>0.2825</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.2641</td>\n",
              "      <td>0.1386</td>\n",
              "      <td>0.1051</td>\n",
              "      <td>0.1343</td>\n",
              "      <td>0.0383</td>\n",
              "      <td>0.0324</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>0.4918</td>\n",
              "      <td>0.6552</td>\n",
              "      <td>0.6919</td>\n",
              "      <td>0.7797</td>\n",
              "      <td>0.7464</td>\n",
              "      <td>0.9444</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8874</td>\n",
              "      <td>0.8024</td>\n",
              "      <td>0.7818</td>\n",
              "      <td>0.5212</td>\n",
              "      <td>0.4052</td>\n",
              "      <td>0.3957</td>\n",
              "      <td>0.3914</td>\n",
              "      <td>0.3250</td>\n",
              "      <td>0.3200</td>\n",
              "      <td>0.3271</td>\n",
              "      <td>0.2767</td>\n",
              "      <td>0.4423</td>\n",
              "      <td>0.2028</td>\n",
              "      <td>0.3788</td>\n",
              "      <td>0.2947</td>\n",
              "      <td>0.1984</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>0.1306</td>\n",
              "      <td>0.4182</td>\n",
              "      <td>0.3835</td>\n",
              "      <td>0.1057</td>\n",
              "      <td>0.1840</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.1674</td>\n",
              "      <td>0.0583</td>\n",
              "      <td>0.1401</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.0621</td>\n",
              "      <td>0.0203</td>\n",
              "      <td>0.0530</td>\n",
              "      <td>0.0742</td>\n",
              "      <td>0.0409</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>0.6333</td>\n",
              "      <td>0.7060</td>\n",
              "      <td>0.5544</td>\n",
              "      <td>0.5320</td>\n",
              "      <td>0.6479</td>\n",
              "      <td>0.6931</td>\n",
              "      <td>0.6759</td>\n",
              "      <td>0.7551</td>\n",
              "      <td>0.8929</td>\n",
              "      <td>0.8619</td>\n",
              "      <td>0.7974</td>\n",
              "      <td>0.6737</td>\n",
              "      <td>0.4293</td>\n",
              "      <td>0.3648</td>\n",
              "      <td>0.5331</td>\n",
              "      <td>0.2413</td>\n",
              "      <td>0.5070</td>\n",
              "      <td>0.8533</td>\n",
              "      <td>0.6036</td>\n",
              "      <td>0.8514</td>\n",
              "      <td>0.8512</td>\n",
              "      <td>0.5045</td>\n",
              "      <td>0.1862</td>\n",
              "      <td>0.2709</td>\n",
              "      <td>0.4232</td>\n",
              "      <td>0.3043</td>\n",
              "      <td>0.6116</td>\n",
              "      <td>0.6756</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.4719</td>\n",
              "      <td>0.4647</td>\n",
              "      <td>0.2587</td>\n",
              "      <td>0.2129</td>\n",
              "      <td>0.2222</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.0176</td>\n",
              "      <td>0.1348</td>\n",
              "      <td>0.0744</td>\n",
              "      <td>0.0130</td>\n",
              "      <td>0.0106</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>0.0881</td>\n",
              "      <td>0.1992</td>\n",
              "      <td>0.0184</td>\n",
              "      <td>0.2261</td>\n",
              "      <td>0.1729</td>\n",
              "      <td>0.2131</td>\n",
              "      <td>0.0693</td>\n",
              "      <td>0.2281</td>\n",
              "      <td>0.4060</td>\n",
              "      <td>0.3973</td>\n",
              "      <td>0.2741</td>\n",
              "      <td>0.3690</td>\n",
              "      <td>0.5556</td>\n",
              "      <td>0.4846</td>\n",
              "      <td>0.3140</td>\n",
              "      <td>0.5334</td>\n",
              "      <td>0.5256</td>\n",
              "      <td>0.2520</td>\n",
              "      <td>0.2090</td>\n",
              "      <td>0.3559</td>\n",
              "      <td>0.6260</td>\n",
              "      <td>0.7340</td>\n",
              "      <td>0.6120</td>\n",
              "      <td>0.3497</td>\n",
              "      <td>0.3953</td>\n",
              "      <td>0.3012</td>\n",
              "      <td>0.5408</td>\n",
              "      <td>0.8814</td>\n",
              "      <td>0.9857</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>0.6121</td>\n",
              "      <td>0.5006</td>\n",
              "      <td>0.3210</td>\n",
              "      <td>0.3202</td>\n",
              "      <td>0.4295</td>\n",
              "      <td>0.3654</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>0.1576</td>\n",
              "      <td>0.0681</td>\n",
              "      <td>0.0294</td>\n",
              "      <td>0.0241</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>0.4152</td>\n",
              "      <td>0.3952</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.4135</td>\n",
              "      <td>0.4528</td>\n",
              "      <td>0.5326</td>\n",
              "      <td>0.7306</td>\n",
              "      <td>0.6193</td>\n",
              "      <td>0.2032</td>\n",
              "      <td>0.4636</td>\n",
              "      <td>0.4148</td>\n",
              "      <td>0.4292</td>\n",
              "      <td>0.5730</td>\n",
              "      <td>0.5399</td>\n",
              "      <td>0.3161</td>\n",
              "      <td>0.2285</td>\n",
              "      <td>0.6995</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.7262</td>\n",
              "      <td>0.4724</td>\n",
              "      <td>0.5103</td>\n",
              "      <td>0.5459</td>\n",
              "      <td>0.2881</td>\n",
              "      <td>0.0981</td>\n",
              "      <td>0.1951</td>\n",
              "      <td>0.4181</td>\n",
              "      <td>0.4604</td>\n",
              "      <td>0.3217</td>\n",
              "      <td>0.2828</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.1979</td>\n",
              "      <td>0.2444</td>\n",
              "      <td>0.1847</td>\n",
              "      <td>0.0841</td>\n",
              "      <td>0.0692</td>\n",
              "      <td>0.0528</td>\n",
              "      <td>0.0357</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>0.0046</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0       1       2       3       4   ...      56      57      58      59  60\n",
              "0  0.0200  0.0371  0.0428  0.0207  0.0954  ...  0.0180  0.0084  0.0090  0.0032   R\n",
              "1  0.0453  0.0523  0.0843  0.0689  0.1183  ...  0.0140  0.0049  0.0052  0.0044   R\n",
              "2  0.0262  0.0582  0.1099  0.1083  0.0974  ...  0.0316  0.0164  0.0095  0.0078   R\n",
              "3  0.0100  0.0171  0.0623  0.0205  0.0205  ...  0.0050  0.0044  0.0040  0.0117   R\n",
              "4  0.0762  0.0666  0.0481  0.0394  0.0590  ...  0.0072  0.0048  0.0107  0.0094   R\n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqwF5M6YN9v8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fd4903e1-e7dc-4a3f-cd71-55af404b94e2"
      },
      "source": [
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(208, 61)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3HaZ-lhN-a0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "4f4c86c9-677a-478f-e437-8162fc2b48c7"
      },
      "source": [
        "# готовим данные для нейросети\n",
        "dataset = df.values # берем значения без индексов\n",
        "X = dataset[:, :-1].astype(float) # присваиваем float данным с эхолота\n",
        "Y = dataset[:,-1] # выделяем последний столбец в Y\n",
        "Y[Y=='R'] = '0'   # 0 - для всех, кроме мин\n",
        "Y[Y=='M'] = '1'   # 1 - для мин\n",
        "Y = Y.astype(int)   # переводим Y в int\n",
        "print(X.shape , Y.shape)\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(208, 60) (208,)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irSXFli8QW3h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85532be9-eea0-4c04-96ae-ad3b7ab7a78e"
      },
      "source": [
        "# разделяем данные на тестовую и обучающую выборки\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# X, Y - разделяемые выборки\n",
        "# test_size=0.2 - 20% не проверочную выборку\n",
        "# shuffle=True - перемешать данные\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, shuffle=True)\n",
        "\n",
        "# проверяем размерности\n",
        "print('X: ', x_train.shape, x_test.shape, '\\t Y: ',  y_train.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X:  (166, 60) (42, 60) \t Y:  (166,) (42,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJfzcPkNZkjF",
        "colab_type": "text"
      },
      "source": [
        "### Эталонная сеть:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWaW-UYdQXaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam # алгоритм для настройки скорости обучения сети\n",
        "\n",
        "# функция, создающая нейронную сеть\n",
        "def createModel():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(60, input_dim=60, activation='relu'))\n",
        "  model.add(Dense(30, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  # Компилируем сеть\n",
        "  model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXYha2uFUp80",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "1b41b314-6ac0-4880-d7a4-ff5455974e49"
      },
      "source": [
        "# создаем пустую сеть и обучаем ее\n",
        "model = createModel()\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=8,\n",
        "          epochs=100,\n",
        "          verbose=0)\n",
        "\n",
        "scores_train = model.evaluate(x_train, y_train, verbose=1)\n",
        "print('Результаты на обучающей выборке: ', scores_train)\n",
        "scores_test = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Результаты на тестовой выборке: ',scores_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 1.0000\n",
            "Результаты на обучающей выборке:  [0.014162193052470684, 1.0]\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.1857 - accuracy: 0.9048\n",
            "Результаты на тестовой выборке:  [0.1856997311115265, 0.9047619104385376]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9evZDiL_ZXrP",
        "colab_type": "text"
      },
      "source": [
        "### повышаем точность до 90%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9e9PSFZZSiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# создаем нейронную сеть\n",
        "# ПОМНИМ О ТОМ, ЧТО ЧЕМ МЕНЬШЕ ВЫБОРКА - ТЕМ ПРОЩЕ СЕТЬ!!\n",
        "def createModel2(n):\n",
        "  model2 = Sequential()\n",
        "  model2.add(Dense(n, input_dim=60, activation='relu'))\n",
        "  model2.add(Dense(1, activation='sigmoid'))\n",
        "  # Компилируем сеть (тут я ускорил в 5 раз скорость обучения)\n",
        "  model2.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.005), metrics=['accuracy'])\n",
        "\n",
        "  return model2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oNyM0jxZyww",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "1afc73cb-d071-402b-a493-1867b7dba034"
      },
      "source": [
        "# создаем пустую сеть и обучаем ее в 5-ти тестовых прогонах\n",
        "n = [120]\n",
        "for j in n:\n",
        "  print('\\n Число нейронов: ', j)\n",
        "  for i in range(5):\n",
        "    model2 = createModel2(j)\n",
        "    # задание условий установки обучения после 5-го ухудшения 'loss'\n",
        "    early_stopping = EarlyStopping(monitor ='loss', patience=5, restore_best_weights = True)\n",
        "    model2.fit(x_train, y_train, batch_size=12, epochs=200, verbose=0, callbacks=[early_stopping])\n",
        "\n",
        "    #print('Результаты на обучающей выборке: ', model2.evaluate(x_train, y_train, verbose=1))\n",
        "    score_test = model2.evaluate(x_test, y_test, verbose=1)\n",
        "    print('Результаты на тестовой выборке: ', score_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Число нейронов:  120\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f51e021b0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1494 - accuracy: 0.9048\n",
            "Результаты на тестовой выборке:  [0.14944487810134888, 0.9047619104385376]\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f51795ce620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1144 - accuracy: 0.9762\n",
            "Результаты на тестовой выборке:  [0.11436201632022858, 0.976190447807312]\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f517a722bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1811 - accuracy: 0.9048\n",
            "Результаты на тестовой выборке:  [0.18107812106609344, 0.9047619104385376]\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f5194c81268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.1011 - accuracy: 0.9762\n",
            "Результаты на тестовой выборке:  [0.10108629614114761, 0.976190447807312]\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f5194c81378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1074 - accuracy: 0.9286\n",
            "Результаты на тестовой выборке:  [0.10739497095346451, 0.9285714030265808]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvXb6A5PZUEk",
        "colab_type": "text"
      },
      "source": [
        "### Вывод:\n",
        "1. исходил из того, что чем меньше примеров, тем проще должна быть сеть\n",
        "2. поставил большое количество эпох и автоматическую остановку при ухудшении loss после 5-й эпохи подряд\n",
        "3. после экспериментов с числом нейронов, увеличил их до 120\n",
        "4. в 5 раз ускорил  обучение (думаю, тем самым немного ушел от раннего переобучения)\n",
        "5. с размером выборки решил не экпериментировать, тк он и там чрезвычайно мал\n",
        "6. для надежности делал по 5 прогонов"
      ]
    }
  ]
}